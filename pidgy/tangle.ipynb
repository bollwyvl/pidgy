{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tangling/translating code\n",
    "\n",
    "tangling code, as presented by donald knuth, converts a document language into a programming language. the original implementation converts `\".WEB\"` files to valid pascal - `\".PAS\"` - files. the `pidgy` approach begins with [markdown] text\n",
    "that converts to `IPython`.\n",
    "[Markdown]: #\n",
    "[Python]: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import typing, IPython, pidgy.util, ast, textwrap, markdown_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tangling `pidgy` uses block level lexical analysis to separate non-code and code lines of code in an input;\n",
    "`pidgy` does not take any opinion on inline level markdown syntax. the `PythonRender` uses the `markdown_it`\n",
    "module for parsing markdown; past versions of `pidgy` have tried `#pandoc, mistune, and mistletoe`. `markdown_it`\n",
    "is the preferred parser because it provides line numbers for markdown tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Tangle(pidgy.compat.markdown.Markdown):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            kwargs['renderer_cls'] = kwargs.get('renderer_cls', PythonRender)\n",
    "            super().__init__(*args, **kwargs)\n",
    "            [self.block.ruler.before(\n",
    "                \"code\",\n",
    "                \"front_matter\",\n",
    "                __import__('functools').partial(pidgy.util.frontMatter, x),\n",
    "                {\"alt\": [\"paragraph\", \"reference\", \"blockquote\", \"list\"]},\n",
    "            ) for x in \"-+\"]\n",
    "            self.block.ruler.before(\n",
    "                \"reference\", \"footnote_def\", markdown_it.extensions.footnote.index.footnote_def, {\"alt\": [\"paragraph\", \"reference\"]}\n",
    "            )\n",
    "            self.disable('html_block')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the primary goal of the `pidgy` lexical analysis to separate non-code and code lines when the markdown is _pythonified_. both indented block code and\n",
    "code fences determine the heuristics for entangling the non-code and code strings. while developing `pidgy`, we've purposefully avoided defining any heuristics for code fenced languages. if author's prefer they can executed code in `pidgy` code fences if no language is supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Pythonify(pidgy.compat.markdown.Renderer):\n",
    "        QUOTES = '\"\"\"', \"'''\"\n",
    "    \n",
    "        def noncode(self, tokens, idx, env):\n",
    "            token, range, prior = None, slice(None), slice(*tokens[-1].map)\n",
    "            if idx < len(tokens):\n",
    "                token = tokens[idx]\n",
    "                range, prior = slice(*tokens[idx].map), slice(*tokens[idx-1].map) if idx else slice(0,0)                \n",
    "            \n",
    "            non_code = pidgy.util.dedent_block(''.join(env['src'][prior.stop:range.start]))\n",
    "            non_code = self.indent(self.hanging_indent(non_code, env), env)\n",
    "            if not env.get('quoted', False):\n",
    "                non_code = self.quote(non_code, trailing=';' if token is None else '')\n",
    "            return non_code\n",
    "        \n",
    "        def code_block(self, tokens, idx, options, env):\n",
    "            code = self.noncode(tokens, idx, env) + pidgy.util.quote_docstrings(self.token_to_str(tokens, idx, env))\n",
    "            return self.update_env(code, tokens, idx, env) or code\n",
    "        \n",
    "        def fence(self, tokens, idx, options, env):\n",
    "            \"We'll only recieve fences without a lang.\"\n",
    "            code =  self.noncode(tokens, idx, env) + textwrap.indent(\n",
    "                pidgy.util.quote_docstrings(pidgy.util.unfence(self.token_to_str(tokens, idx, env))), ' '*4\n",
    "            )\n",
    "            return self.update_env(code, tokens, idx, env) or code\n",
    "\n",
    "                \n",
    "        def update_env(self, code, tokens, idx, env):\n",
    "            next = self.get_next_code_token(tokens, idx)\n",
    "            env.update(base_indent=pidgy.util.trailing_indent(code))\n",
    "\n",
    "            extra_indent = 0\n",
    "            if next:\n",
    "                extra_indent = max(0, pidgy.util.lead_indent(env['src'][slice(*next.map)]) -env['base_indent'])\n",
    "            if not extra_indent and code.rstrip().endswith(\":\"):\n",
    "                extra_indent += 4\n",
    "            rstrip = code.rstrip()\n",
    "            env.update(\n",
    "                extra_indent=extra_indent,\n",
    "                continued=rstrip.endswith('\\\\'), \n",
    "                quoted=rstrip.rstrip('\\\\').endswith(self.QUOTES)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pidgy` includes special affordances affordances for common notation like front matter, footnotes as annotations, and bulleted lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PythonRender(Pythonify):\n",
    "        def front_matter(self, tokens, idx, options, env):\n",
    "            token, code = tokens[idx], self.token_to_str(tokens, idx, env)\n",
    "            if token.markup == '+++':\n",
    "                code = F'''locals().update(__import__('toml').loads(\"\"\"{code}\"\"\".partition('+++')[2].rpartition('+++')[0]))\\n'''\n",
    "            elif token.markup == '---':\n",
    "                code = F'''locals().update(__import__('ruamel.yaml').yaml.safe_load(\"\"\"{code}\"\"\".partition('---')[2].rpartition('---')[0]))\\n'''            \n",
    "            return self.indent(code, env)\n",
    "\n",
    "            \n",
    "        def reference(self, tokens, idx, options, env, *, re='link_item'):\n",
    "            token, code = tokens[idx], self.token_to_str(tokens, idx, env)\n",
    "            if env['quoted']:\n",
    "                return code\n",
    "            \n",
    "            expr  = \"{\"+F\"\"\"x.group(1): x.group(2).rstrip() for x in __import__('pidgy').util.{re}.finditer({\n",
    "                self.quote(textwrap.dedent(code), trailing=\")}\").rstrip()\n",
    "            }\"\"\"\n",
    "            if not env['continued']:\n",
    "                expr = \"\"\"locals()[\"__annotations__\"] = {**%s, **locals().get('__annotations__', {})}\"\"\"%expr\n",
    "            code = self.noncode(tokens, idx, env) + self.indent(expr + \"\\n\", env)\n",
    "            return code\n",
    "        \n",
    "        def footnote_reference_open(self, tokens, idx, options, env):\n",
    "            return self.reference(tokens, idx, options, env, re='footnote_item')\n",
    "        \n",
    "        def bullet_list_open(self, tokens, idx, options, env):\n",
    "            token, code = tokens[idx], self.token_to_str(tokens, idx, env)\n",
    "            if env['quoted']:\n",
    "                return code\n",
    "            if env['continued']:\n",
    "                return self.indent(\n",
    "                    (F\"\"\"[x.group().rstrip().partition(' ')[2] for x in __import__('pidgy').util.list_item.finditer({\n",
    "                        self.quote(textwrap.dedent(code), trailing=')]')\n",
    "                    }\\n\"\"\"), env)\n",
    "            code = self.quote(textwrap.dedent(code), trailing=';')\n",
    "            code = self.indent(self.hanging_indent(code, env), env)\n",
    "            return code\n",
    "\n",
    "        ordered_list_open = bullet_list_open "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tangle` is a public function for tangling markdown to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def tangle(str:str)->str:\n",
    "        translate = Tangle()\n",
    "        return translate.render(''.join(str or []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pidgy` interfaces with `IPython` as an input transform manager trait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class pidgyManager(pidgy.base.Trait, IPython.core.inputtransformer2.TransformerManager):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.tangle = Tangle()\n",
    "        def transform_cell(self, cell): \n",
    "            if self.enabled:\n",
    "                cell = self.tangle.render(cell)\n",
    "            return super(type(self), self).transform_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more langauge features\n",
    "\n",
    "`pidgy` experiments extra language features for python, using the same system\n",
    "that IPython uses to add features like line and cell magics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, IPython introduced a convention that allows top level await statements outside of functions. Building of this convenience, `pidgy` allows for top-level __return__ and __yield__ statements.  These statements are replaced with the an IPython display statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class ExtraSyntax(ast.NodeTransformer):\n",
    "        def visit_FunctionDef(self, node): return node\n",
    "        visit_AsyncFunctionDef = visit_FunctionDef        \n",
    "\n",
    "        def visit_Return(self, node):\n",
    "            replace = ast.parse('''__import__('IPython').display.display()''').body[0]\n",
    "            replace.value.args = node.value.elts if isinstance(node.value, ast.Tuple) else [node.value]\n",
    "            return ast.copy_location(replace, node)\n",
    "\n",
    "        def visit_Expr(self, node):\n",
    "            if isinstance(node.value, (ast.Yield, ast.YieldFrom)):  return ast.copy_location(self.visit_Return(node.value), node)\n",
    "            return node\n",
    "\n",
    "        visit_Expression = visit_Expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know naming is hard, there is no point focusing on it. `pidgy` allows authors\n",
    "to use emojis as variables in python. They add extra color and expression to the narrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def demojize(lines, delimiters=('_', '_')):\n",
    "        str = ''.join(lines or [])\n",
    "        import tokenize, emoji, stringcase; tokens = []\n",
    "        try:\n",
    "            for token in list(tokenize.tokenize(\n",
    "                __import__('io').BytesIO(str.encode()).readline)):\n",
    "                if token.type == tokenize.ERRORTOKEN:\n",
    "                    string = emoji.demojize(token.string, delimiters=delimiters\n",
    "                                           ).replace('-', '_').replace(\"’\", \"_\")\n",
    "                    if tokens and tokens[-1].type == tokenize.NAME: tokens[-1] = tokenize.TokenInfo(tokens[-1].type, tokens[-1].string + string, tokens[-1].start, tokens[-1].end, tokens[-1].line)\n",
    "                    else: tokens.append(\n",
    "                        tokenize.TokenInfo(\n",
    "                            tokenize.NAME, string, token.start, token.end, token.line))\n",
    "                else: tokens.append(token)\n",
    "            return tokenize.untokenize(tokens).decode()\n",
    "        except BaseException: ...\n",
    "        return ''.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
