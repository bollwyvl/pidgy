{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# by *convention* __test__ing should be interactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ...; o = __name__ == '__main__'; ...;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive testing is manual quality assurance of notebook source.  This extension introduces an automated testing approach that combines __doctest__, __unittest__, and __hypothesis__ to test interactive strings, functions, and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conventions set forth by `rites.hypothesis` will encourage better types annotations, docstrings, and reusabulity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing During Interactive Programming Is Efficient\n",
    "\n",
    "In interactive mode, the `testing` extension will execute tests when:\n",
    "    \n",
    "* An unassigned string literatal containing doctests.\n",
    "* Docstrings in functions definitions and class defitions.\n",
    "* Functions containing complete annotations.\n",
    "* Classes containing runTest\n",
    "* TestCase classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from doctest import DocTestCase, DocTestSuite, DocTest, DocTestParser, DocTestFinder, testmod\n",
    "    from ast import *\n",
    "    from functools import wraps, partial\n",
    "    from dataclasses import dataclass, field\n",
    "    from IPython import get_ipython\n",
    "    from inspect import *\n",
    "    from hypothesis import given, strategies, strategies as st, assume, HealthCheck, Verbosity, settings, find\n",
    "    from unittest import TestCase, TextTestRunner, TestSuite\n",
    "    __all__ = 'infer',\n",
    "    \n",
    "    def infer(object, ghetto=True, module=None)->('test', dict, any):\n",
    "        \"\"\"Use the hypothesis inference systems to create automated types from the annotations or ghetto typing.\n",
    "        \n",
    "        \n",
    "        >>> def f(int, b:int): ...\n",
    "        >>> test, annotations, returns = infer(f)\n",
    "        >>> assert all(str in annotations for str in ('int', 'b'))\n",
    "        \"\"\"\n",
    "        from unittest import FunctionTestCase\n",
    "        from inspect import getfullargspec\n",
    "        \n",
    "        spec = getfullargspec(object)\n",
    "        \n",
    "        annotations = dict(**spec.annotations)\n",
    "        returns = annotations.pop('return', None)\n",
    "        \n",
    "        if not spec.args: \n",
    "            return FunctionTestCase(object), annotations, returns\n",
    "        \n",
    "        module = module or __import__('__main__')\n",
    "        \n",
    "        if ghetto:\n",
    "            for arg in spec.args:\n",
    "                if arg in annotations: continue\n",
    "                try:\n",
    "                    thing = eval(arg, vars(module))\n",
    "                except NameError: continue\n",
    "                if isinstance(thing, (type, list)):\n",
    "                    annotations[arg] = thing\n",
    "                \n",
    "        if not (spec.defaults or spec.kwonlydefaults):\n",
    "            try:\n",
    "                annotations = {\n",
    "                    str: st.from_type(object) if isinstance(object, type) and getattr(object, '__name__', '') != 'object'\n",
    "                    else object if isinstance(object, st.SearchStrategy)\n",
    "                    else st.one_of(list(map(st.just, object)))\n",
    "                    for str, object in annotations.items()\n",
    "                }\n",
    "                if annotations:\n",
    "                    return FunctionTestCase(given(**annotations)(object)), annotations.copy(), returns\n",
    "            except: ...\n",
    "                \n",
    "        return None, annotations, returns\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test(Testing, *, context=None, module=None):\n",
    "        \"\"\"Test an object contains \n",
    "        \n",
    "        >>> testing = Testing()\n",
    "        >>> testing.objects = ['f']\n",
    "        >>> def f():...\n",
    "        >>> demo = __import__('types').ModuleType('demo')\n",
    "        >>> test(testing, module=__import__('__main__'), context=setattr(demo, 'f', f) or demo)\n",
    "        \"\"\"\n",
    "        from types import ModuleType\n",
    "        global mod\n",
    "        \n",
    "        module, context = ModuleType('__main__'), context or __import__('__main__')\n",
    "        tests = list()\n",
    "        mod = module\n",
    "        module.__test__ = getattr(module, '__test__', {})\n",
    "        \n",
    "        while Testing.objects:\n",
    "            name = Testing.objects.pop(0)\n",
    "            object = getattr(context, name)\n",
    "            setattr(module, name, object)\n",
    "            if isinstance(object, type):\n",
    "                if issubclass(object, TestCase): \n",
    "                    tests.append(object())\n",
    "                elif hasattr(object, 'runTest'):\n",
    "                    def runTest(): return object.runTest(object)\n",
    "                    tests.append(FunctionTestCase(wraps(object.runTest)(runTest)))\n",
    "            elif callable(object):\n",
    "                test, annotations, returns = infer(object)\n",
    "                if (returns is not None) and callable(returns) ^ isinstance(returns, type)and len(annotations) is 1:\n",
    "                    try:\n",
    "                        find(*annotations.values(), lambda x: returns(object(x)))\n",
    "                    except:\n",
    "                        assert False, f\"\"\"NoSuchExample for {object} satifies {returns} \"\"\"\n",
    "                elif test: tests.append(test)\n",
    "                    \n",
    "            if getattr(object, '__name__', None):\n",
    "                tests.extend(map(DocTestCase, DocTestFinder().find(object)))\n",
    "                \n",
    "        try:\n",
    "            mod = module\n",
    "            runner = TextTestRunner(verbosity=1)\n",
    "            tests and runner.run(TestSuite(set(tests)))            \n",
    "        except: ...\n",
    "        Testing.objects = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NodeTransformer\n",
    "\n",
    "... accumulates the testable functions and classes in the parsed ast.  It must be `callable` to use with `get_ipython().events.callback['post_run_cell']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from dataclasses import dataclass, field\n",
    "\n",
    "    @dataclass\n",
    "    class Testing(NodeTransformer):\n",
    "        \"\"\"Testing must be callable so it can be using as an {IPython.core.events.EventManager}\n",
    "        >>> assert callable(Testing())\n",
    "        \"\"\"\n",
    "        objects = list()\n",
    "        \n",
    "        def visit_FunctionDef(Testing, node): \n",
    "            \"\"\"Identify FunctionDef and ClassDef as potentially testable objects.\n",
    "            \n",
    "            >>> visitor = Testing()\n",
    "            >>> assert visitor.visit(ast.parse('def f(): ...'))\n",
    "            >>> assert visitor.objects\n",
    "            \"\"\"\n",
    "            Testing.objects.append(node.name)\n",
    "            return node\n",
    "        \n",
    "        visit_ClassDef = visit_FunctionDef\n",
    "        \n",
    "        __call__ = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "    %unload_ext rites.hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def unload_ipython_extension(ip=None):\n",
    "        \"\"\">>> unload_ipython_extension()\"\"\"\n",
    "        transformers = []\n",
    "        ip = ip or get_ipython()\n",
    "        ip.events.callbacks['post_run_cell'] = [object for object in ip.events.callbacks['post_run_cell'] if not isinstance(object, Testing)]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    %reload_ext rites.hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_ipython_extension(ip=get_ipython()):\n",
    "        \"\"\"\n",
    "        >>> ip = load_ipython_extension()\n",
    "        >>> assert any(isinstance(object, Testing) for object in ip.ast_transformers)\n",
    "        \"\"\"\n",
    "        settings.register_profile('ip', settings(\n",
    "            suppress_health_check=(HealthCheck.return_value,),\n",
    "            verbosity=Verbosity.normal,))\n",
    "        unload_ipython_extension(ip)\n",
    "        object = Testing()\n",
    "        ip.ast_transformers.append(object)        \n",
    "        ip.events.register('post_run_cell', object)\n",
    "        settings.load_profile('ip')\n",
    "        return ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if o: load_ipython_extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def a_function_without_tests(a, b):\n",
    "        return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "    def any_function_with_a_True_docstring_is_doctested(a, b):\n",
    "        \"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "    def a_function_with_a_doctest(a, b):\n",
    "        \"\"\"Test {a_function_with_a_doctest} with {doctest}\n",
    "        \n",
    "        >>> assert a_function_with_a_doctest(10, 32) is 42\n",
    "        \"\"\"\n",
    "        return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.182s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "    from hypothesis.errors import UnsatisfiedAssumption\n",
    "    ct = 0\n",
    "    def test_a_function_with_edge_cases(a: int, b: int):\n",
    "        \"\"\"{test_a_function_with_edge_cases} uses the type annotations to infer a hypothesis strategy to test the function\n",
    "        \n",
    "        >>> assert test_a_function_with_edge_cases(10, 32) is 42\n",
    "        >>> try:\n",
    "        ...     test_a_function_with_edge_cases(0, 0)\n",
    "        ...     assert None, 'This should not throw an Exception'\n",
    "        ... except UnsatisfiedAssumption:\n",
    "        ...     assert True, 'Hypothesis throws a special unsatisfiable error.'\n",
    "        \"\"\"\n",
    "        global ct\n",
    "        ct += 1\n",
    "        __import__('hypothesis').assume(a or b)\n",
    "        assert a+b\n",
    "        return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<function test_a_function_with_edge_cases at 0x10cc35d08> was automatically evaluated 103 times.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    f\"{test_a_function_with_edge_cases} was automatically evaluated {ct} times.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `doctest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    assert callable(Testing())\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    visitor = Testing()\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert visitor.visit(ast.parse('def f(): ...'))\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert visitor.objects\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert a_function_with_a_doctest(10, 32) is 42\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    def f(int, b:int): ...\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    test, annotations, returns = infer(f)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert all(str in annotations for str in ('int', 'b'))\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    ip = load_ipython_extension()\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert any(isinstance(object, Testing) for object in ip.ast_transformers)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    testing = Testing()\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    testing.objects = ['f']\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    def f():...\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    demo = __import__('types').ModuleType('demo')\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    test(testing, module=__import__('__main__'), context=setattr(demo, 'f', f) or demo)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    assert test_a_function_with_edge_cases(10, 32) is 42\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    try:\n",
      "        test_a_function_with_edge_cases(0, 0)\n",
      "        assert None, 'This should not throw an Exception'\n",
      "    except UnsatisfiedAssumption:\n",
      "        assert True, 'Hypothesis throws a special unsatisfiable error.'\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    unload_ipython_extension()\n",
      "Expecting nothing\n",
      "ok\n",
      "3 items had no tests:\n",
      "    __main__\n",
      "    __main__.a_function_without_tests\n",
      "    __main__.any_function_with_a_True_docstring_is_doctested\n",
      "8 items passed all tests:\n",
      "   1 tests in __main__.Testing\n",
      "   3 tests in __main__.Testing.visit_FunctionDef\n",
      "   1 tests in __main__.a_function_with_a_doctest\n",
      "   3 tests in __main__.infer\n",
      "   2 tests in __main__.load_ipython_extension\n",
      "   5 tests in __main__.test\n",
      "   2 tests in __main__.test_a_function_with_edge_cases\n",
      "   1 tests in __main__.unload_ipython_extension\n",
      "18 tests in 11 items.\n",
      "18 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TestResults(failed=0, attempted=18), 'for all of the doctests.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    o and __import__('doctest').testmod(verbose=2), \"\"\"for all of the doctests.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nbconvert execution\n",
    "\n",
    "    __import__('nbconvert').preprocessors.execute.ExecutePreprocessor().preprocess(__import__('nbformat').read('hypothesis.ipynb', 4),{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
