{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`pidgin.testing`](testing.md.ipynb) provides discussion and tools for __testing__ notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import ast, IPython, re, functools, traitlets, typing as t, doctest, IPython, textwrap, importnb, collections, contextlib\n",
    "    from importnb.utils.pytest_importnb import AlternativeModule, AlternativeSourceText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from pidgin import shell, tangle\n",
    "    from pidgin.applications import loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if __name__ == '__main__':\n",
    "        %reload_ext pidgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>testing should be useful indenpendent of pidgin.</p>\n",
       "<p>The weave step assures that code objects are executed.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing should be useful indenpendent of pidgin.\n",
    "\n",
    "The weave step assures that code objects are executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Notebooks as test objects</h2>\n",
       "<p>A frequent motivator for notebook authors is to express a unit of thought in narrative and code.  This method of hypothesis testing is similar to manual testing in software development.  Traditional software manufacturing organizations will have supplement manual testing with automated testing and continuous integration.</p>\n",
       "<p>Outside of the interactive context, notebooks currently find wide use as documentation tool.</p>\n",
       "<p><em>Literate programming will have been mentioned as a documentation tool.</em>\n",
       "<em>Doctesting will be described somewhere else.</em></p>\n",
       "<p>Currently, there is little word processing support.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Notebooks as test objects\n",
    "\n",
    "A frequent motivator for notebook authors is to express a unit of thought in narrative and code.  This method of hypothesis testing is similar to manual testing in software development.  Traditional software manufacturing organizations will have supplement manual testing with automated testing and continuous integration.\n",
    "\n",
    "Outside of the interactive context, notebooks currently find wide use as documentation tool.\n",
    "\n",
    "_Literate programming will have been mentioned as a documentation tool._\n",
    "_Doctesting will be described somewhere else._\n",
    "\n",
    "Currently, there is little word processing support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Documentation and Testing</h3>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Documentation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class OutputChecker(__import__('doctest').OutputChecker):\n",
    "        def check_output(self, want, got, optionflags): return True if want == '...\\n' else super().check_output(want, got, optionflags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @contextlib.contextmanager\n",
    "    def wrapped_compiler(shell):\n",
    "        def compiler(input, *args, **kwargs):\n",
    "            return compile(ast.Interactive(body=shell.transform_ast(ast.parse(shell.transform_cell(textwrap.indent(input, ' '*4)))).body), *args, **kwargs)\n",
    "        yield setattr(doctest, 'compile', compiler)\n",
    "        try: del doctest.compile\n",
    "        except: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run_docstring_examples(str, shell, verbose=False, compileflags=None):\n",
    "        finder, runner = doctest.DocTestFinder(verbose=verbose), doctest.DocTestRunner(verbose=verbose, optionflags=doctest.ELLIPSIS)\n",
    "        with wrapped_compiler(shell):\n",
    "            for test in finder.find(str, name=shell.user_module.__name__): \n",
    "                test.globs = vars(shell.user_module)\n",
    "                test.globs.update({**shell.user_ns, **vars(shell.user_module)})\n",
    "                runner.run(test, compileflags=compileflags, clear_globs=False)\n",
    "        return runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run_test(test, shell, verbose=False, compileflags=None):\n",
    "        runner = doctest.DocTestRunner(verbose=verbose, optionflags=doctest.ELLIPSIS)\n",
    "        with wrapped_compiler(shell):\n",
    "            test.globs = vars(shell.user_module)\n",
    "            test.globs.update({**shell.user_ns, **vars(shell.user_module)})\n",
    "            runner.run(test, compileflags=compileflags, clear_globs=False)\n",
    "        return runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Doctest(shell.Shell):                \n",
    "        def run_cell(Formatter, text, *args, **kwargs):\n",
    "            if isinstance(text, IPython.core.interactiveshell.ExecutionResult): text = text.info.raw_cell\n",
    "            run_docstring_examples(text, Formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_cell_doctests` runs any `doctest`s found in the raw source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PidginModule(AlternativeModule): loader = tangle.Pidgin\n",
    "    class MarkdownModule(AlternativeModule): loader = loaders.MarkdownImporter\n",
    "    class PidginTests(metaclass=AlternativeSourceText): modules = PidginModule, MarkdownModule\n",
    "    pytest_collect_file = PidginTests.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>&gt;&gt;&gt; assert 0, \"Currently it is not possible to test dynamically generated outputs.  eneter robot lab.\"\n",
       "</code></pre>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Line 1, in _test_\n",
      "Failed example:\n",
      "    assert 0, \"Currently it is not possible to test dynamically generated outputs.  eneter robot lab.\"\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"/Users/tonyfast/anaconda/envs/p6/lib/python3.6/doctest.py\", line 1330, in __run\n",
      "        compileflags, 1), test.globs)\n",
      "      File \"<doctest _test_[0]>\", line 2, in <module>\n",
      "    AssertionError: Currently it is not possible to test dynamically generated outputs.  eneter robot lab.\n"
     ]
    }
   ],
   "source": [
    ">>> assert 0, \"Currently it is not possible to test dynamically generated outputs.  eneter robot lab.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>&gt;&gt;&gt; assert 0, \"Hypothesis\"\n",
       "</code></pre>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Line 1, in _test_\n",
      "Failed example:\n",
      "    assert 0, \"Hypothesis\"\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"/Users/tonyfast/anaconda/envs/p6/lib/python3.6/doctest.py\", line 1330, in __run\n",
      "        compileflags, 1), test.globs)\n",
      "      File \"<doctest _test_[0]>\", line 2, in <module>\n",
      "    AssertionError: Hypothesis\n"
     ]
    }
   ],
   "source": [
    ">>> assert 0, \"Hypothesis\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
