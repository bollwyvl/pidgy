{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tangle` and `transform_cell` modules are non-pidgin source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import ast, IPython, re, functools,traitlets, doctest, textwrap, mistune, types, importnb, typing as t, pygments\n",
    "    if __name__ == '__main__': \n",
    "        %reload_ext pidgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def markdown_to_python(str: \"Markdown Source\") -> \"Valid Python Source\": \n",
    "        return BlockLexer().parse(''.join(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @functools.wraps(markdown_to_python)\n",
    "    def markdown_to_python_wrapper(line: str, cell: str): \n",
    "        return IPython.display.HTML(pygments.highlight(markdown_to_python(cell), pygments.lexers.PythonLexer(), pygments.formatters.HtmlFormatter(noclasses=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_ipython_extension(shell):\n",
    "        unload_ipython_extension(shell)\n",
    "        shell.input_transformer_manager.cleanup_transforms.insert(0, Tangle(parent=shell))\n",
    "        for i, transformer in enumerate(shell.input_transformers_cleanup):\n",
    "            try:\n",
    "                if transformer.initial_re.pattern[1:4] == '>>>':\n",
    "                    shell.input_transformers_cleanup.pop(i)\n",
    "                    break\n",
    "            except: ...\n",
    "             \n",
    "        try: IPython.core.magic.register_cell_magic(markdown_to_python_wrapper)\n",
    "        except: shell.log.error(\"Unable to load the pidgin.tangle cell magic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Tangle(traitlets.config.LoggingConfigurable): \n",
    "        markdown = traitlets.Bool(True, help=\"\"\"Convert __Markdown__ source to Python & execute the block code.\"\"\")\n",
    "        log_level = traitlets.Int(10)\n",
    "        def __call__(self, lines: t.List[str]) -> t.List[str]:\n",
    "            if self.markdown:\n",
    "                source = markdown_to_python(lines + ['\\n']).splitlines(True)\n",
    "                if source:\n",
    "                    self.parent.log.log(self.log_level, F\"In[{len(self.parent.user_ns['In'])}]:\")\n",
    "                    self.parent.log.log(self.log_level, ''.join(source))\n",
    "                    return source\n",
    "            return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class BlockLexer(mistune.BlockLexer):\n",
    "        raw = unindented = indented = None\n",
    "        def __init__(BlockLexer, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            BlockLexer.original = None\n",
    "            BlockLexer.raw, BlockLexer.unindented, BlockLexer.indented, BlockLexer.min_indent = [], [], [], 0\n",
    "            \n",
    "        def parse_block_code(BlockLexer, m=None):\n",
    "            if m:\n",
    "                if get_line_indent(get_last_line(BlockLexer.raw)) == get_line_indent(m.string[slice(*m.span())]):\n",
    "                    return BlockLexer.parse_generic(m)\n",
    "            \n",
    "            BlockLexer.format()\n",
    "            BlockLexer.raw.extend(m and BlockLexer.pop_text(m) or [])\n",
    "            if m: super().parse_block_code(m)\n",
    "            BlockLexer.indent()\n",
    "\n",
    "            \n",
    "        def parse(self, text: str, rules=None) -> t.List[t.Dict]: \n",
    "            if text.startswith('%%'): return text\n",
    "            \n",
    "            text = text.lstrip('//')\n",
    "            if any((self.original, self.raw, self.unindented, self.indented)): \n",
    "                return super().parse(text, rules)\n",
    "            \n",
    "            text = strip_blank_lines(text)\n",
    "            self.original = ''.join(text).splitlines(True)\n",
    "            \n",
    "            super().parse(text, rules) # returns tokens but we dont need them.\n",
    "            \n",
    "            while self.original:  self.raw.append(self.original.pop(0))\n",
    "            self.min_indent = self.min_indent or 4\n",
    "            self.format(punc=';')\n",
    "            self.indent()\n",
    "            return textwrap.dedent(''.join(self.indented))\n",
    "                    \n",
    "        def parse_generic(self, m) -> str: \n",
    "            self.raw.extend(self.pop_text(m))\n",
    "            \n",
    "        parse_doctest = parse_block_html = parse_block_quote = parse_fences =\\\n",
    "        parse_heading = parse_hrule = parse_lheading = parse_newline =\\\n",
    "        parse_nptable = parse_paragraph = parse_table = parse_text =  parse_generic\n",
    "\n",
    "        def parse_def_footnotes(self, m):\n",
    "            self.format()\n",
    "            text = ''.join(self.pop_text(m))\n",
    "            key, sep, body = text.lstrip('[').lstrip('^').partition(']:')\n",
    "            key = quote(key)\n",
    "            quoted = quote(body.lstrip())\n",
    "            self.unindented.extend(F\"\"\"globals()[{key}] = {quoted if quoted.strip() else \"None\"}\"\"\".splitlines(True))\n",
    "            \n",
    "        def parse_def_links(self, m):\n",
    "            self.parse_block_code()\n",
    "            text = ''.join(self.pop_text(m))\n",
    "            key, sep, body = text.lstrip('[').lstrip('^').partition(']:')\n",
    "            key = quote(key)\n",
    "\n",
    "            self.unindented.extend(F\"\"\"globals()['__context__'] = globals().get('__context__', dict()); globals()['__context__'][{key}] = {quote(body.lstrip())}\"\"\".splitlines(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def clear_original(BlockLexer) -> None:\n",
    "        while BlockLexer.original and not BlockLexer.original[0].strip(): \n",
    "            BlockLexer.raw += [BlockLexer.original.pop(0)]\n",
    "        \n",
    "    def pop_text(BlockLexer, m) -> str:\n",
    "        text = []\n",
    "        lines = m.string[slice(*m.span())].splitlines(True)\n",
    "        # Remove empty lines\n",
    "        while lines and not lines[0].strip(): lines.pop(0)\n",
    "\n",
    "        # Drop the lines from the original body\n",
    "        if BlockLexer.original:\n",
    "            while lines:\n",
    "                line = lines.pop(0)\n",
    "                if line.strip():\n",
    "                    while line.strip() not in BlockLexer.original[0]: \n",
    "                        text += [BlockLexer.original.pop(0)]\n",
    "                    text += [BlockLexer.original.pop(0)]\n",
    "        return text\n",
    "\n",
    "    def format(BlockLexer, punc: \"Punctation on the quoted code\"=''):\n",
    "        BlockLexer.clear_original()            \n",
    "        if BlockLexer.raw: \n",
    "            last_line = get_last_line(BlockLexer.indented).rstrip()\n",
    "            lines = [line for line in BlockLexer.raw]\n",
    "            if not last_line.endswith(('\"\"\"', \"'''\", \"---\", \"'''\\\\\", '\"\"\"\\\\',)):\n",
    "                lines = [quote(lines, punc)]\n",
    "            BlockLexer.unindented.extend(lines)\n",
    "            BlockLexer.raw = []\n",
    "\n",
    "\n",
    "    def indent(BlockLexer):\n",
    "        # Extract the first line of the current code block.\n",
    "        first_line = get_first_line(BlockLexer.raw)\n",
    "        # Construct the code we'll \n",
    "        code, body = ''.join(BlockLexer.raw), ''.join(BlockLexer.unindented)\n",
    "\n",
    "        # The previous last line append\n",
    "        last_line = get_last_line(BlockLexer.indented)\n",
    "\n",
    "        # The current indent level so far.\n",
    "        prior_indent = get_line_indent(last_line)\n",
    "\n",
    "        # Does the last line enter a block statement\n",
    "        definition = last_line.rstrip().endswith(':')\n",
    "        returns = _has_return(BlockLexer.indented)\n",
    "\n",
    "        this_indent = get_line_indent(get_first_line(BlockLexer.raw))\n",
    "\n",
    "\n",
    "        # Assign the minimum indent \n",
    "        if not BlockLexer.min_indent: \n",
    "            BlockLexer.min_indent = this_indent\n",
    "\n",
    "\n",
    "\n",
    "        if this_indent < BlockLexer.min_indent:\n",
    "            code = textwrap.indent(code, ' '*(BlockLexer.min_indent-this_indent))\n",
    "            this_indent = get_line_indent(get_first_line(code.splitlines()))\n",
    "\n",
    "\n",
    "        # Normalize the indent we'll assign the body+code\n",
    "        indent = max(BlockLexer.min_indent, (returns and min or max)(prior_indent, this_indent))        \n",
    "\n",
    "        if definition:\n",
    "            if prior_indent >= indent:\n",
    "                indent = (prior_indent + 4)\n",
    "\n",
    "            body = hanging_indent(textwrap.indent(body, ' '*BlockLexer.min_indent), ' '*(indent-BlockLexer.min_indent))\n",
    "        else:\n",
    "            body = textwrap.indent(body, ' '*indent)\n",
    "\n",
    "        # Cell Magics\n",
    "        if code.lstrip().startswith('%%'):\n",
    "            # Cell magics can be split across __Markdown__ blocks.  With this \n",
    "            # approach conditional blocks can be used with magics.\n",
    "            code = (' '*this_indent) + importnb.loader.dedent(code)\n",
    "            # might have to add lines if line sized changed.\n",
    "\n",
    "        if BlockLexer.min_indent:\n",
    "            BlockLexer.indented.extend(body.splitlines(True) + code.splitlines(True))\n",
    "            BlockLexer.unindented = []\n",
    "        BlockLexer.raw = []\n",
    "        return ''       \n",
    "\n",
    "    \n",
    "    BlockLexer.indent = indent\n",
    "    BlockLexer.format = format\n",
    "    BlockLexer.clear_original = clear_original\n",
    "    BlockLexer.pop_text = pop_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def unload_ipython_extension(shell):\n",
    "        shell.input_transformer_manager.cleanup_transforms = [object for object in shell.input_transformer_manager.cleanup_transforms if not isinstance(object, Tangle)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def quote(str, punc=''):\n",
    "        str, leading_ws = ''.join(str), []\n",
    "        lines = str.splitlines(True)\n",
    "        _ = '\"\"\"'\n",
    "        if _ in str: _ = \"'''\"\n",
    "        if not str.strip(): _ = punc = ''\n",
    "        while lines and (not lines[0].strip()): leading_ws.append(lines.pop(0))    \n",
    "        str = ''.join(lines)\n",
    "        end = len(str.rstrip())\n",
    "        str, ending_ws = str[:end], str[end:]\n",
    "        if str and str.endswith(_[0]): str += ' '                    \n",
    "        return F\"{''.join(leading_ws)}{_}{str}{_}{punc}{ending_ws}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_first_line` get the first non-`iter`able strings in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_first_line(lines, line=''):\n",
    "        for line in lines or ['']: \n",
    "            if line.strip(): break\n",
    "        return line\n",
    "    def get_last_line(lines, line=''): return get_first_line(reversed(lines), line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_line_indent` computes the indent of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_line_indent(line):  return len(line) - len(line.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _has_return(code):\n",
    "        code = '\\n'.join(code)\n",
    "        if 'return ' not in code: return False\n",
    "        code = importnb.loader.dedent(code)\n",
    "        try:\n",
    "            node = ast.parse(code)\n",
    "            while hasattr(node, 'body'): node = node.body[-1]\n",
    "            return isinstance(node, ast.Return)\n",
    "        except: ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def hanging_indent(str, indent: str, *, out=\"\"\"\"\"\") -> str:\n",
    "        for line in str.splitlines(True):\n",
    "            if not line.strip(): out += line\n",
    "            else:\n",
    "                if out.strip(): out += line\n",
    "                else: out += indent+line\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def strip_blank_lines(str): return '\\n'.join(str if str.strip() else '' for str in ''.join(str).splitlines())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
