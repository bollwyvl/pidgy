{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from IPython import get_ipython; ip = get_ipython()\n",
    "    %reload_ext pidgin.tangle\n",
    "\n",
    "`import pidgin.tangle` modifies the `get_ipython().input_transformer_manager` to accept __Markdown__ source.  The `pidgin.tangle` module\n",
    "exports:\n",
    "    \n",
    "* `pidgin.tangle.markdown_to_python` - is a semi-lossless __Markdown__ to __Python__ converter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import doctest, re, ast, mistune, textwrap, functools, itertools, IPython, importnb, fnmatch\n",
    "    __all__ = 'markdown_to_python',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`quote` wrotes non code objects in triple ticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def quote(str, punc=''):\n",
    "        str, leading_ws = ''.join(str), []\n",
    "        lines = str.splitlines(True)\n",
    "        _ = '\"\"\"'\n",
    "        if _ in str: _ = \"'''\"\n",
    "        if not str.strip(): _ = punc = ''\n",
    "        while lines and (not lines[0].strip()): leading_ws.append(lines.pop(0))    \n",
    "        str = ''.join(lines)\n",
    "        end = len(str.rstrip())\n",
    "        str, ending_ws = str[:end], str[end:]\n",
    "        if str and str.endswith(_[0]): str += ' '                    \n",
    "        return F\"{''.join(leading_ws)}{_}{str}{_}{punc}{ending_ws}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_first_line` get the first non-`iter`able strings in `lines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_first_line(lines, line=''):\n",
    "        for line in lines or ['']: \n",
    "            if line.strip(): break\n",
    "        return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_line_indent` computes the indent of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_line_indent(line):  return len(line) - len(line.lstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __Lexer__ s only consider coarse features of the markdown spec.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _has_return(code):\n",
    "        code = '\\n'.join(code)\n",
    "        if 'return ' not in code: return False\n",
    "        code = importnb.loader.dedent(code)\n",
    "        try:\n",
    "            node = ast.parse(code)\n",
    "            while hasattr(node, 'body'): node = node.body[-1]\n",
    "            return isinstance(node, ast.Return)\n",
    "        except: ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def hanging_indent(str, indent):\n",
    "        out = \"\"\"\"\"\"\n",
    "        for line in str.splitlines(True):\n",
    "            if not line.strip(): \n",
    "                out += line\n",
    "            else:\n",
    "                if out.strip(): out += line\n",
    "                else: out += indent+line\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PidginBlockGrammar(mistune.BlockGrammar):\n",
    "        doctest = doctest.DocTestParser._EXAMPLE_RE\n",
    "        block_html = re.compile(\n",
    "            r'^ *(?:%s|%s|%s) *(?:\\n{2,}|\\s*$)' % (\n",
    "                r'<!--[\\s\\S]*?-->|<!DOCTYPE [\\s\\S]*?>|<\\?[\\s\\S]*?\\?>',\n",
    "                r'<(%s)((?:%s)*?)>([\\s\\S]*?)<\\/\\1>' % (mistune._block_tag, mistune._valid_attr),\n",
    "                r'<%s(?:%s)*?\\s*\\/?>' % (mistune._block_tag, mistune._valid_attr)))       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PidginBlockLexer(mistune.BlockLexer): \n",
    "        grammar_class = PidginBlockGrammar        \n",
    "        @staticmethod\n",
    "        def to_string(m): return m.string[slice(*m.span())].splitlines(True)\n",
    "\n",
    "        def parse_doctest(self, m):\n",
    "            self.tokens.append({'type': 'doctest', 'text': m.string[slice(*m.span())]})\n",
    "        \n",
    "    PidginBlockLexer.default_rules = list(PidginBlockLexer.default_rules)\n",
    "    PidginBlockLexer.default_rules.insert(\n",
    "        PidginBlockLexer.default_rules.index('block_quote'), 'doctest'\n",
    "    )\n",
    "    PidginBlockLexer.footnote_rules = list(PidginBlockLexer.footnote_rules)\n",
    "    PidginBlockLexer.footnote_rules.insert(\n",
    "        PidginBlockLexer.footnote_rules.index('block_quote'), 'doctest'\n",
    "    )\n",
    "    PidginBlockLexer.list_rules = list(PidginBlockLexer.list_rules)\n",
    "    PidginBlockLexer.list_rules.insert(\n",
    "        PidginBlockLexer.list_rules.index('block_quote'), 'doctest'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class TanglePidginBlockLexer(PidginBlockLexer):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.original = None\n",
    "            self.raw, self.unindented, self.indented = [], [], []\n",
    "            self.min_indent = 0\n",
    "            \n",
    "        def parse(self, text, rules=None): \n",
    "            \n",
    "            if any((self.original, self.raw, self.unindented, self.indented)): \n",
    "                return super().parse(text, rules)\n",
    "            \n",
    "            self.original = ''.join(text).splitlines(True)\n",
    "            tokens = super().parse(text, rules)\n",
    "            \n",
    "            while self.original:  self.raw.append(self.original.pop(0))\n",
    "            self.min_indent = self.min_indent or 4\n",
    "            self.format(punc=';')\n",
    "            self.indent()\n",
    "            final = ''.join(self.indented)\n",
    "            return final\n",
    "            \n",
    "        def clear_original(self):\n",
    "            while self.original and not self.original[0].strip(): \n",
    "                self.raw += [self.original.pop(0)]\n",
    "                \n",
    "        def pop_text(self, m)->str:\n",
    "            text = []\n",
    "            lines = self.to_string(m)\n",
    "            # Remove empty lines\n",
    "            while lines and not lines[0].strip(): lines.pop(0)\n",
    "            \n",
    "            # Drop the lines from the original body\n",
    "            if self.original:\n",
    "                while lines:\n",
    "                    line = lines.pop(0)\n",
    "                    if line.strip():\n",
    "                        while line.strip() not in self.original[0]: \n",
    "                            text += [self.original.pop(0)]\n",
    "                        text += [self.original.pop(0)]\n",
    "            return text\n",
    "        \n",
    "        def parse_generic(self, m): \n",
    "            self.raw.extend(self.pop_text(m))\n",
    "            \n",
    "        parse_doctest = parse_block_html = parse_block_quote = parse_fences =\\\n",
    "        parse_heading = parse_hrule = parse_lheading = parse_newline =\\\n",
    "        parse_nptable = parse_paragraph = parse_table = parse_text =  parse_generic\n",
    "        \n",
    "        def parse_block_code(self, m=None):\n",
    "            # The body goes about the code, the buffer is non-code.\n",
    "            self.format()\n",
    "            self.raw.extend(m and self.pop_text(m) or [])\n",
    "            m and super().parse_block_code(m)\n",
    "            self.indent()\n",
    "            \n",
    "        def format(self, punc=''):\n",
    "            self.clear_original()            \n",
    "            if self.raw: \n",
    "                last_line = get_first_line(reversed(self.indented)).rstrip()\n",
    "                lines = [line for line in self.raw]\n",
    "                if not last_line.endswith(('\"\"\"', \"'''\")):\n",
    "                    lines = [quote(lines, punc)]\n",
    "                self.unindented.extend(lines)\n",
    "                self.raw = []\n",
    "                        \n",
    "            \n",
    "        def indent(self):\n",
    "            # Extract the first line of the current code block.\n",
    "            first_line = get_first_line(self.raw)\n",
    "            # Construct the code we'll \n",
    "            code = ''.join(self.raw)                            \n",
    "            body = ''.join(self.unindented)            \n",
    "            \n",
    "            # The previous last line append\n",
    "            last_line = get_first_line(reversed(self.indented))\n",
    "            \n",
    "            # The current indent level so far.\n",
    "            prior_indent = get_line_indent(last_line)\n",
    "\n",
    "            # Does the last line enter a block statement\n",
    "            definition = last_line.rstrip().endswith(':')\n",
    "            returns = _has_return(self.indented)\n",
    "\n",
    "            this_indent = get_line_indent(get_first_line(self.raw))\n",
    "            \n",
    "            # Assign the minimum indent \n",
    "            if not self.min_indent: \n",
    "                self.min_indent = this_indent\n",
    "            \n",
    "            if this_indent < self.min_indent:\n",
    "                code = textwrap.indent(code, ' '*(self.min_indent-this_indent))\n",
    "                this_indent = get_line_indent(get_first_line(code.splitlines()))\n",
    "\n",
    "                \n",
    "            # Normalize the indent we'll assign the body+code\n",
    "            indent = max(self.min_indent, (returns and min or max)(prior_indent, this_indent))        \n",
    "            \n",
    "            if definition:\n",
    "                if prior_indent >= indent:\n",
    "                    indent = (prior_indent + 4)\n",
    "                \n",
    "                body = hanging_indent(textwrap.indent(body, ' '*self.min_indent), ' '*(indent-self.min_indent))\n",
    "            else:\n",
    "                body = textwrap.indent(body, ' '*indent)\n",
    "                \n",
    "            # Cell Magics\n",
    "            if code.lstrip().startswith('%%'):\n",
    "                # Cell magics can be split across __Markdown__ blocks.  With this \n",
    "                # approach conditional blocks can be used with magics.\n",
    "                code = (' '*this_indent) + importnb.loader.dedent(code)\n",
    "                # might have to add lines if line sized changed.\n",
    "                \n",
    "            if self.min_indent:\n",
    "                self.indented.extend(body.splitlines(True) + code.splitlines(True))\n",
    "                self.unindented = []\n",
    "            self.raw = []\n",
    "            return ''       \n",
    "\n",
    "        def parse_def_footnotes(self, m):\n",
    "            self.format()\n",
    "            text = ''.join(self.pop_text(m))\n",
    "            key, sep, body = text.lstrip('[').lstrip('^').partition(']:')\n",
    "            key = quote(key)\n",
    "            quoted = quote(body.lstrip())\n",
    "            self.unindented.extend(F\"\"\"globals()[{key}] = {quoted if quoted.strip() else \"None\"}\"\"\".splitlines(True))\n",
    "            \n",
    "        def parse_def_links(self, m):\n",
    "            self.parse_block_code()\n",
    "            text = ''.join(self.pop_text(m))\n",
    "            key, sep, body = text.lstrip('[').lstrip('^').partition(']:')\n",
    "            key = quote(key)\n",
    "\n",
    "            self.unindented.extend(F\"\"\"globals()[{key}] = globals().get({key}, {quote(body.lstrip(), ')')}\"\"\".splitlines(True))\n",
    "\n",
    "    def markdown_to_python(str)->\"Valid Python Source\": \n",
    "        return TanglePidginBlockLexer().parse(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def transformer(lines: \"that end with a newline.\"): \n",
    "        # Always add a new line\n",
    "        return markdown_to_python(''.join(lines + ['\\n'])).splitlines(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_ipython_extension(ip=None):\n",
    "        ip = ip or IPython.get_ipython()\n",
    "        ip.input_transformer_manager.cleanup_transforms = [transformer] + [\n",
    "            object for object in ip.input_transformer_manager.cleanup_transforms\n",
    "            if object not in {transformer, IPython.core.inputtransformer2.classic_prompt}\n",
    "        ]\n",
    "\n",
    "    def unload_ipython_extension(ip=None):\n",
    "        ip = ip or IPython.get_ipython()\n",
    "        ip.input_transformer_manager.cleanup_transforms = [\n",
    "            object for object in ip.input_transformer_manager.cleanup_transforms\n",
    "            if object is not transformer]\n",
    "    if __name__ == '__main__': load_ipython_extension()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
